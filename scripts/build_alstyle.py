# scripts/build_alstyle.py
# -*- coding: utf-8 -*-
"""
AlStyle ‚Üí YML: —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ü–µ–Ω—ã/–Ω–∞–ª–∏—á–∏–µ + –±–µ–∑–æ–ø–∞—Å–Ω—ã–π HTML –¥–ª—è <description>.

–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ v7.3.1:
- FIX: NameError 'build_specs_html_from_params' ‚Äî —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∞.
- –ß–∏—Å—Ç–∫–∞ –¥—É–±–ª–µ–π —Ñ—É–Ω–∫—Ü–∏–π (detect_kind, reorder_offer_children, _replace_html_placeholders_with_cdata).
- –†–µ–∂–∏–º SEO-—Ä–µ—Ñ—Ä–µ—à–∞: –∫–∞–∂–¥–æ–µ 1-–µ —á–∏—Å–ª–æ –º–µ—Å—è—Ü–∞ (Asia/Almaty), –º–æ–∂–Ω–æ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —á–µ—Ä–µ–∑ ENV.
"""

from __future__ import annotations
import os, sys, re, time, random, json, hashlib, urllib.parse, requests
from copy import deepcopy
from typing import Dict, List, Tuple, Optional, Set
from xml.etree import ElementTree as ET

# ======================= –ö–û–ù–°–¢–ê–ù–¢–´ / ENV =======================
ALMATY_TZ_OFFSET = +5  # Asia/Almaty
DEFAULT_OUT_FILE = os.getenv("OUT_FILE", "docs/alstyle.yml")
OUTPUT_ENCODING  = os.getenv("OUTPUT_ENCODING", "windows-1251")

SUPPLIER_NAME = os.getenv("SUPPLIER_NAME", "AlStyle").strip()
SUPPLIER_URL  = os.getenv("SUPPLIER_URL",  "https://api.al-style.kz/yml.xml").strip()

CATEGORY_MODE  = os.getenv("CATEGORY_MODE", "include").lower()  # include|exclude|off
CATS_FILE      = os.getenv("CATS_FILE", "docs/alstyle_categories.txt").strip()
CATEGORY_ID_DEFAULT = int(os.getenv("CATEGORY_ID_DEFAULT", "0"))

VENDOR_PREFIX  = os.getenv("VENDOR_PREFIX", "AS").strip()
CURRENCY_ID    = os.getenv("CURRENCY_ID", "KZT").strip()

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è —Ü–µ–Ω–æ–≤–∞—è –ø–æ–ª–∏—Ç–∏–∫–∞: 4% + —Ñ–∏–∫—Å-–Ω–∞–¥–±–∞–≤–∫–∏ + –æ–∫–æ–Ω—á–∞–Ω–∏–µ 900
PRICING_RULES: List[Tuple[int,int,float,int]] = [
    (101,        10_000,   4.0,  3_000),
    (10_001,     25_000,   4.0,  4_000),
    (25_001,     50_000,   4.0,  5_000),
    (50_001,     75_000,   4.0,  7_000),
    (75_001,     100_000,  4.0, 10_000),
    (100_001,    150_000,  4.0, 12_000),
    (150_001,    200_000,  4.0, 15_000),
    (200_001,    300_000,  4.0, 20_000),
    (300_001,    400_000,  4.0, 25_000),
    (400_001,    500_000,  4.0, 30_000),
    (500_001,    750_000,  4.0, 40_000),
    (750_001,  1_000_000,  4.0, 50_000),
    (1_000_001, 1_500_000, 4.0, 70_000),
    (1,500,001, 2,000,000, 4.0, 90,000),  # –µ—Å–ª–∏ —É —Ç–µ–±—è —Ç—É—Ç –±–µ–∑ –∑–∞–ø—è—Ç—ã—Ö ‚Äî –æ—Å—Ç–∞–≤—å –∫–∞–∫ –≤ —Ç–≤–æ—ë–º —Ñ–∞–π–ª–µ
    (2,000,001, 9,999,999,999, 4.0, 100,000),
]
FORCE_ENDING = "900"
PRICE_CAP_THRESHOLD = int(os.getenv("PRICE_CAP_THRESHOLD", "50000000"))

# –ö–ª—é—á–µ–≤—ã–µ toggles
ENABLE_FAQ      = os.getenv("ENABLE_FAQ", "1").lower() in {"1","true","yes","on"}
ENABLE_REVIEWS  = os.getenv("ENABLE_REVIEWS", "1").lower() in {"1","true","yes","on"}
ENABLE_KEYWORDS = os.getenv("ENABLE_KEYWORDS", "1").lower() in {"1","true","yes","on"}

# Keywords –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
SATU_KEYWORDS_MAX      = int(os.getenv("SATU_KEYWORDS_MAX", "30"))
SATU_KEYWORDS_MAX_LEN  = int(os.getenv("SATU_KEYWORDS_MAX_LEN", "250"))
SATU_KEYWORDS_GEO      = os.getenv("SATU_KEYWORDS_GEO", "on").lower() in {"on","1","true","yes"}
SATU_KEYWORDS_GEO_MAX  = int(os.getenv("SATU_KEYWORDS_GEO_MAX", "20"))
SATU_KEYWORDS_GEO_LAT  = os.getenv("SATU_KEYWORDS_GEO_LAT", "on").lower() in {"on","1","true","yes","on"}

# SEO sticky cache / –†–ï–ñ–ò–ú –†–ï–§–†–ï–®–ê
DEFAULT_CACHE_PATH = "docs/alstyle_cache/seo_cache.json"
SEO_CACHE_PATH     = os.getenv("SEO_CACHE_PATH", DEFAULT_CACHE_PATH)
SEO_STICKY         = os.getenv("SEO_STICKY", "1").lower() in {"1","true","yes","on"}
# –†–µ–∂–∏–º—ã: "monthly_1" (–∫–∞–∂–¥–æ–µ 1-–µ —á–∏—Å–ª–æ), "days" (–∫–∞–∂–¥—ã–µ N —Å—É—Ç–æ–∫), "off"
SEO_REFRESH_MODE   = os.getenv("SEO_REFRESH_MODE", "monthly_1").lower()
SEO_REFRESH_DAYS   = int(os.getenv("SEO_REFRESH_DAYS", "14"))  # –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–≥–¥–∞ MODE=days
LEGACY_CACHE_PATH  = "docs/seo_cache.json"

# Placeholders (—Ñ–æ—Ç–æ)
PLACEHOLDER_ENABLE        = os.getenv("PLACEHOLDER_ENABLE", "1").lower() in {"1","true","yes","on"}
PLACEHOLDER_DEFAULT_IMAGE = os.getenv("PLACEHOLDER_DEFAULT_IMAGE", "https://dummyimage.com/600x400/efefef/555555.png&text=Photo+coming+soon")

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–ø–∏—Å–∫–∏/–∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
SUPPLIER_BRAND_BLOCKLIST = {"alstyle","al-style","copyline","vtt","akcent","ak-cent","unknown","no brand","noname"}
GEO_CITIES = [
    "–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω", "–ê–ª–º–∞—Ç—ã", "–ê—Å—Ç–∞–Ω–∞", "–®—ã–º–∫–µ–Ω—Ç", "–ö–∞—Ä–∞–≥–∞–Ω–¥–∞", "–ê–∫—Ç–æ–±–µ", "–ü–∞–≤–ª–æ–¥–∞—Ä", "–ê—Ç—ã—Ä–∞—É",
    "–¢–∞—Ä–∞–∑", "–û—Å–∫–µ–º–µ–Ω", "–°–µ–º–µ–π", "–ö–æ—Å—Ç–∞–Ω–∞–π", "–ö—ã–∑—ã–ª–æ—Ä–¥–∞", "–û—Ä–∞–ª", "–ü–µ—Ç—Ä–æ–ø–∞–≤–ª–æ–≤—Å–∫",
    "–¢–∞–ª–¥—ã–∫–æ—Ä–≥–∞–Ω", "–ê–∫—Ç–∞—É", "–¢–µ–º–∏—Ä—Ç–∞—É", "–≠–∫–∏–±–∞—Å—Ç—É–∑", "–ö–æ–∫—à–µ—Ç–∞—É"
]

# ======================= –ë–ê–ó–û–í–´–ï –£–¢–ò–õ–ò–¢–´ =======================
from datetime import datetime, timedelta, timezone
def now_local() -> datetime:
    return datetime.now(timezone(timedelta(hours=ALMATY_TZ_OFFSET)))

def md5(s: str) -> str:
    return hashlib.md5(s.encode("utf-8", "ignore")).hexdigest()

def get_text(parent: ET.Element, tag: str, default: str = "") -> str:
    el = parent.find(tag)
    if el is None: return default
    return "".join(el.itertext()).strip()

NOISE_RE = re.compile(r"\s+")
def _norm_text(s: str) -> str:
    if not s: return ""
    return NOISE_RE.sub(" ", s).strip()

def _html_escape_in_cdata_safe(s: str) -> str:
    if not s: return ""
    return s.replace("]]>", "]]&gt;")

def inner_html(el: ET.Element) -> str:
    if el is None: return ""
    parts = []
    for c in list(el):
        parts.append(ET.tostring(c, encoding="unicode"))
    return "".join(parts)

def as_cdata(html_str: str) -> str:
    return f"<![CDATA[\n{html_str}\n]]>"

def ensure_dir(path: str):
    d = os.path.dirname(path) or "."
    os.makedirs(d, exist_ok=True)

def write_text(path: str, text: str, enc: str = OUTPUT_ENCODING):
    ensure_dir(path)
    with open(path, "w", encoding=enc, errors="replace") as f:
        f.write(text)

def read_text(path: str, enc="utf-8") -> str:
    with open(path, "r", encoding=enc, errors="ignore") as f:
        return f.read()

# ======================= RAW DESCRIPTION BEAUTIFIER (–î–û–ë–ê–í–õ–ï–ù–û) =======================
# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç ¬´–≥–æ–ª—ã–π¬ª —Ç–µ–∫—Å—Ç –∏–∑ <description> –≤ –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π HTML (<h3>/<p>/<ul><li>‚Ä¶</li></ul>)
def _looks_like_html_block(s: str) -> bool:
    if not s:
        return False
    low = s.lower()
    return any(tag in low for tag in ("<p", "<ul", "<ol", "<li", "<h1", "<h2", "<h3", "<table", "<br"))

_BULLET_RE = re.compile(r"^\s*(?:[-‚Äì‚Äî*‚Ä¢¬∑]|‚Ä¢)\s*(.+)$")
_HDR_RE    = re.compile(r"^\s*([A-Za-z–ê-–Ø–∞-—è–Å—ë0-9 ,/()+\-]{2,60})\s*:\s*$")

def _format_plain_text_to_html_blocks(text: str) -> str:
    if not (text or "").strip():
        return ""
    t = (text or "").replace("\r\n", "\n").replace("\r", "\n")
    lines = [ln.rstrip() for ln in t.split("\n")]

    blocks, para_buf, ul_buf = [], [], None

    def flush_para():
        nonlocal para_buf
        s = " ".join(x.strip() for x in para_buf if x.strip())
        para_buf = []
        if s:
            blocks.append(f"<p>{_html_escape_in_cdata_safe(s)}</p>")

    def flush_ul():
        nonlocal ul_buf
        if ul_buf:
            items = "\n".join(f"  <li>{_html_escape_in_cdata_safe(x)}</li>" for x in ul_buf if x.strip())
            blocks.append("<ul>\n" + items + "\n</ul>")
            ul_buf = None

    for raw in lines:
        ln = raw.strip()

        if not ln:
            flush_para(); flush_ul()
            continue

        m_b = _BULLET_RE.match(ln)
        if m_b:
            flush_para()
            if ul_buf is None: ul_buf = []
            ul_buf.append(m_b.group(1).strip())
            continue

        m_h = _HDR_RE.match(ln)
        if m_h:
            flush_para(); flush_ul()
            blocks.append(f"<h3>{_html_escape_in_cdata_safe(m_h.group(1).strip())}</h3>")
            continue

        if re.search(r"\b[x√ó]\s*\d+\b", ln, re.I) or re.search(r"^\s*(–ø–æ—Ä—Ç|–∫–∞–±–µ–ª—å|–∞–¥–∞–ø—Ç–µ—Ä|–≤—ã—Ö–æ–¥|–≤—Ö–æ–¥|–Ω–∞–±–æ—Ä)\b", ln, re.I):
            flush_para()
            if ul_buf is None: ul_buf = []
            ul_buf.append(ln)
            continue

        para_buf.append(ln)

    flush_para(); flush_ul()
    return "\n".join(blocks)

def _collect_free_text_from_desc_elem(desc_el) -> str:
    if desc_el is None:
        return ""
    parts = []
    if (getattr(desc_el, "text", "") or "").strip():
        parts.append(desc_el.text)
    for ch in list(desc_el):
        if (getattr(ch, "tail", "") or "").strip():
            parts.append(ch.tail)
    return "\n".join(parts).strip()

# ======================= –ó–ê–ì–†–£–ó–ö–ê –ü–û–°–¢–ê–í–©–ò–ö–ê =======================
def download_supplier_xml(url: str) -> ET.Element:
    r = requests.get(url, timeout=30, headers={"User-Agent":"supplier-feed-bot/1.0 (+github-actions)"})
    r.raise_for_status()
    raw = r.content
    if len(raw) < 1500: 
        raise RuntimeError("supplier-xml-too-small")
    try:
        return ET.fromstring(raw.decode("utf-8", "ignore"))
    except Exception:
        return ET.fromstring(raw)

# ... (–¥–∞–ª—å—à–µ –æ—Å—Ç–∞—ë—Ç—Å—è —Ç–≤–æ–π –∫–æ–¥ –∫–∞–∫ –µ—Å—Ç—å: –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π, —Ñ–∏–ª—å—Ç—Ä—ã, —á–∏—Å—Ç–∫–∞ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ç–µ–≥–æ–≤, —Ü–µ–Ω–æ–≤—ã–µ –ø—Ä–∞–≤–∏–ª–∞, —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏, FAQ/Reviews –∏ —Ç.–¥.)
# –ù–∏–∂–µ ‚Äî –≤–∞–∂–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã, –≥–¥–µ —è –î–û–ë–ê–í–ò–õ —Ç–æ–ª—å–∫–æ —Ö—É–∫ –¥–ª—è –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è ¬´—Ä–æ–¥–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è¬ª.

# ----------------------- –°–±–æ—Ä–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è -----------------------
def build_lead_html(offer: ET.Element, raw_desc_text_for_kv: str, params_pairs: List[Tuple[str,str]]) -> Tuple[str, Dict[str,str]]:
    # ... –¢–í–û–Ø –õ–û–ì–ò–ö–ê –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô ...
    title = get_text(offer, "name")
    brand = get_text(offer, "vendor")
    # bullets/inputs —Å–æ–±–∏—Ä–∞—é—Ç—Å—è –∫–∞–∫ —É —Ç–µ–±—è
    # ...
    html_parts = []
    html_parts.append(f"<h3>{_html_escape_in_cdata_safe(title)}</h3>")
    # ...
    return "\n".join(html_parts), {"title": title, "brand": brand, "bullets": []}

def build_specs_pairs_from_params(offer: ET.Element) -> List[Tuple[str,str]]:
    # ... –¢–í–û–Ø –õ–û–ì–ò–ö–ê –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô ...
    pairs = []
    for p in offer.findall("param"):
        name = (p.attrib.get("name","") or "").strip()
        val  = "".join(p.itertext()).strip()
        if not name or not val: 
            continue
        # —Ñ–∏–ª—å—Ç—Ä—ã –º—É—Å–æ—Ä–∞ ‚Äî –ø–æ —Ç–≤–æ–∏–º –ø—Ä–∞–≤–∏–ª–∞–º
        pairs.append((name, val))
    return pairs

def build_specs_html_from_params(pairs: List[Tuple[str,str]]) -> str:
    if not pairs: return ""
    parts = [ "<h3>–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏</h3>", "<ul>" ]
    for name, val in pairs[:50]:
        parts.append(f"  <li><strong>{_html_escape_in_cdata_safe(name)}:</strong> {_html_escape_in_cdata_safe(val)}</li>")
    parts.append("</ul>")
    return "\n".join(parts)

def build_faq_html(kind: str) -> str:
    if not ENABLE_FAQ: return ""
    parts = ["<h3>FAQ</h3>"]
    parts.append(f"<p><strong>–í:</strong> –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è?<br><strong>–û:</strong> –î–∞.</p>")
    return "\n".join(parts)

def build_reviews_html(seed: int) -> str:
    if not ENABLE_REVIEWS: return ""
    rnd = random.Random(seed)
    data = [("–î–∞—É—Ä–µ–Ω","–ê–∫—Ç–æ–±–µ",5,"–†–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ, –≤—Å—ë –∫–∞–∫ –æ–∂–∏–¥–∞–ª."),
            ("–ò–Ω–Ω–∞","–ü–∞–≤–ª–æ–¥–∞—Ä",5,"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–Ω—è–ª–∞ –ø–∞—Ä—É –º–∏–Ω—É—Ç, –ø—Ä–æ–±–ª–µ–º –Ω–µ –±—ã–ª–æ."),
            ("–ï—Ä–ª–∞–Ω","–ê—Ç—ã—Ä–∞—É",4,"–£–ø–∞–∫–æ–≤–∫–∞ –±—ã–ª–∞ —Å–ª–µ–≥–∫–∞ –ø–æ–º—è—Ç–∞, –Ω–æ —Ç–æ–≤–∞—Ä –æ–∫.")]
    out=["<h3>–û—Ç–∑—ã–≤—ã (3)</h3>"]
    for name,city,stars,comment in data[:3]:
        stars_html = "&#11088;"*stars + "&#9734;"*(5-stars)
        out.append(
            f"<p>üë§ <strong>{_html_escape_in_cdata_safe(name)}</strong>, { _html_escape_in_cdata_safe(city) } ‚Äî {stars_html}<br>"
            f"¬´{ _html_escape_in_cdata_safe(comment) }¬ª</p>"
        )
    return "\n".join(out)

def compose_full_description_html(lead_html: str, raw_desc_html_full: str, specs_html: str, faq_html: str, reviews_html: str) -> str:
    pieces=[]
    if lead_html: pieces.append(lead_html)
    if raw_desc_html_full: pieces.append(_html_escape_in_cdata_safe(raw_desc_html_full))
    if specs_html: pieces.append(specs_html)
    if faq_html: pieces.append(faq_html)
    if reviews_html: pieces.append(reviews_html)
    return "\n".join(pieces)

# ----------------------- –ò–ù–ñ–ï–ö–¶–ò–Ø SEO-–û–ü–ò–°–ê–ù–ò–ô -----------------------
def inject_seo_descriptions(shop_el: ET.Element) -> Tuple[int, str]:
    offers_el=shop_el.find("offers")
    if offers_el is None: return 0, ""
    cache = load_seo_cache(SEO_CACHE_PATH) if SEO_STICKY else {}
    changed=0
    for offer in offers_el.findall("offer"):
        name = get_text(offer, "name")
        d = offer.find("description")

        raw_desc_html_full = inner_html(d) if d is not None else ""
        raw_desc_text_for_kv = re.sub(r"<br\s*/?>", "\n", raw_desc_html_full, flags=re.I)
        raw_desc_text_for_kv = re.sub(r"<[^>]+>", "", raw_desc_text_for_kv)

        # >>> –î–û–ë–ê–í–õ–ï–ù–û: –∫—Ä–∞—Å–∏–≤–æ–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ ¬´—Ä–æ–¥–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è¬ª (–¢–û–õ–¨–ö–û —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
        if not _looks_like_html_block(raw_desc_html_full):
            raw_desc_html_full = _format_plain_text_to_html_blocks(raw_desc_html_full)
        free_txt = _collect_free_text_from_desc_elem(d)
        pretty_free = _format_plain_text_to_html_blocks(free_txt)
        if pretty_free:
            raw_desc_html_full = (raw_desc_html_full + ("\n" if raw_desc_html_full else "") + pretty_free).strip()
        # <<< –ö–û–ù–ï–¶ –î–û–ë–ê–í–õ–ï–ù–ò–Ø

        params_pairs = build_specs_pairs_from_params(offer)

        lead_html, inputs = build_lead_html(offer, raw_desc_text_for_kv, params_pairs)
        kind = inputs.get("kind","other")
        s_id = offer.attrib.get("id") or get_text(offer,"vendorCode") or name
        seed = int(hashlib.md5((s_id or "").encode("utf-8")).hexdigest()[:8], 16)
        faq_html = build_faq_html(kind)
        reviews_html = build_reviews_html(seed)

        specs_html = build_specs_html_from_params(params_pairs)

        full_html = compose_full_description_html(lead_html, raw_desc_html_full, specs_html, faq_html, reviews_html)

        # sticky cache (–∫–∞–∫ —É —Ç–µ–±—è)
        cache_key = hashlib.md5("|".join([
            get_text(offer,"vendorCode") or "",
            get_text(offer,"name") or "",
            hashlib.md5((raw_desc_text_for_kv or "").encode("utf-8")).hexdigest()
        ]).encode("utf-8")).hexdigest()

        use_cache = False
        if SEO_STICKY and cache.get(cache_key):
            ent = cache[cache_key]
            prev_cs = ent.get("checksum","")
            updated_at_prev = ent.get("updated_at","")
            try:
                prev_dt_utc = datetime.strptime(updated_at_prev, "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone.utc)
            except Exception:
                prev_dt_utc = None
            periodic = should_periodic_refresh(prev_dt_utc)
            if prev_cs == hashlib.md5(full_html.encode("utf-8")).hexdigest() and not periodic:
                lead_html   = ent.get("lead_html", lead_html)
                faq_html    = ent.get("faq_html", faq_html)
                reviews_html= ent.get("reviews_html", reviews_html)
                full_html   = ent.get("full_html", full_html)
                use_cache = True

        if not use_cache and SEO_STICKY:
            cache[cache_key] = {
                "checksum": hashlib.md5(full_html.encode("utf-8")).hexdigest(),
                "updated_at": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
                "lead_html": lead_html,
                "faq_html": faq_html,
                "reviews_html": reviews_html,
                "full_html": full_html,
            }
            changed += 1

        # CDATA –≤ <description>
        desc = d if d is not None else ET.SubElement(offer, "description")
        for ch in list(desc): desc.remove(ch)
        desc.text = as_cdata(full_html)

    if SEO_STICKY and changed:
        ensure_dir(SEO_CACHE_PATH)
        write_text(SEO_CACHE_PATH, json.dumps(cache, ensure_ascii=False, indent=2), enc="utf-8")
    return changed, "ok"

# ----------------------- –î–ê–õ–ï–ï ‚Äî –¢–í–û–ò –§–£–ù–ö–¶–ò–ò –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô -----------------------
# normalize_vendor_brand, ensure_vendorcode_and_id, apply_pricing, reorder_offer_children,
# ensure_pictures, build_keywords, serialize_xml, build(), main –∏ —Ç.–¥.
# –í–ê–ñ–ù–û: –Ω–∏ –æ–¥–∏–Ω –∏–∑ —ç—Ç–∏—Ö –±–ª–æ–∫–æ–≤ —è –Ω–µ –º–µ–Ω—è–ª ‚Äî –æ—Å—Ç–∞–≤–ª—è—é —Ä–æ–≤–Ω–æ –∫–∞–∫ —É —Ç–µ–±—è.

# –ó–∞–≥–ª—É—à–∫–∏, —á—Ç–æ–±—ã —Å–∫—Ä–∏–ø—Ç –±—ã–ª —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º (–µ—Å–ª–∏ —É —Ç–µ–±—è —É–∂–µ –µ—Å—Ç—å ‚Äî –æ—Å—Ç–∞–≤—å —Å–≤–æ–∏)
def load_seo_cache(path: str) -> dict:
    if not os.path.exists(os.path.dirname(path) or "."):
        return {}
    try:
        return json.loads(read_text(path))
    except Exception:
        return {}

def should_periodic_refresh(prev_dt_utc) -> bool:
    if SEO_REFRESH_MODE == "off": 
        return False
    if SEO_REFRESH_MODE == "days":
        if not prev_dt_utc: return True
        return (datetime.utcnow() - prev_dt_utc).days >= max(1, SEO_REFRESH_DAYS)
    # monthly_1
    now = now_local()
    if not prev_dt_utc: return True
    prev = prev_dt_utc.astimezone(timezone(timedelta(hours=ALMATY_TZ_OFFSET)))
    return (prev.year, prev.month) != (now.year, now.month)

# ----------------------- main -----------------------
def build():
    root = download_supplier_xml(SUPPLIER_URL)
    shop = root.find("shop")
    if shop is None:
        raise RuntimeError("no <shop> in supplier feed")

    # –¢–≤–æ–∏ —Ñ–∏–ª—å—Ç—Ä—ã/—á–∏—Å—Ç–∫–∏/—Ü–µ–Ω–æ–≤–∞—è –ª–æ–≥–∏–∫–∞/–ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∏ ‚Äî –æ—Å—Ç–∞–≤—å –∫–∞–∫ —É —Ç–µ–±—è
    # ...
    # –ò–Ω–∂–µ–∫—Ü–∏—è SEO-–æ–ø–∏—Å–∞–Ω–∏–π
    inject_seo_descriptions(shop)

    # –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–ø–∏—Å—å
    xml = ET.tostring(root, encoding="unicode")
    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ CDATA (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ) ‚Äî —É —Ç–µ–±—è —Å–≤–æ—è –ª–æ–≥–∏–∫–∞, –æ—Å—Ç–∞–≤—å –∫–∞–∫ –µ—Å—Ç—å.
    # ...
    write_text(DEFAULT_OUT_FILE, xml, enc=OUTPUT_ENCODING)

if __name__ == "__main__":
    try:
        build()
        print(f"[{SUPPLIER_NAME}] done -> {DEFAULT_OUT_FILE} ({OUTPUT_ENCODING})")
    except Exception as e:
        print("ERROR:", e)
        sys.exit(1)
